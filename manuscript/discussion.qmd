---
editor:
  markdown:
    wrap: 80
---

## Discussion

The GIAB HG002 v5.0 benchmark represents a substantial advance in variant
benchmarking, providing the first comprehensive assembly-based benchmark that
spans autosomes and sex chromosomes for both small and structural variants
across three human reference genomes. By leveraging the highly curated Q100
HG002 assembly, this benchmark confidently includes variants in many genomic
regions that were inaccessible to previous mapping-based or less complete
assembly-based approaches, including segmental duplications, long tandem
repeats, and complex gene families. The expansion is particularly pronounced
for challenging repetitive regions, with 5.6 times more small variants in
segmental duplications, 4.6 times more in tandem repeats, and 2-fold more in
homopolymers compared to v4.2.1. For structural variants, the benchmark
doubles the number of confident calls relative to v0.6 and, critically,
provides exact phased sequence representations rather than merged alleles,
enabling assessment of base-level accuracy of SV calls.

Because early drafts of the v5.0 benchmarks were made public for community
feedback, many publications have already demonstrated their utility. The draft
benchmarks were used in the development and validation of new variant calling
tools, including sawfish for larger SVs and lower coverages, DNAscope for
hybrid short and long read calling, gcSV and blend-seq for combined short and
long read SV calling, and pangenome-aware DeepVariant. The SV benchmark was
shown to substantially enhance performance evaluation in challenging repetitive
regions, where most false positives and false negatives concentrate even for
long-read callers. The combined phased small variants and SVs enabled
development of benchmarking tools vcfdist2 and aardvark that jointly assess
phased small variants and SVs, which is important in repetitive regions with
complex variants. These efforts illustrate the value of making draft benchmarks
openly available to the community during development, and the importance of
expanding benchmarks into difficult genomic regions where most errors occur.

### DeFrABB as a reusable framework

The DeFrABB pipeline provides a modular, reproducible framework for generating
assembly-based variant benchmarks from any high-quality diploid assembly.
Because benchmark generation involves numerous parameter choices — from
assembly-to-reference alignment settings to exclusion region definitions — a
transparent, configurable pipeline is essential for reproducibility and
iteration. DeFrABB encodes these decisions in version-controlled configuration
files and produces provenance records of each run, enabling others to
regenerate benchmarks with modified parameters or updated assemblies. The
pipeline's reference-agnostic design allowed generation of matched benchmarks
for GRCh37, GRCh38, and T2T-CHM13v2.0 from a single assembly, reducing the
effort needed to support users on different references. As highly accurate
diploid assemblies become available for additional individuals and ancestries,
DeFrABB can facilitate rapid generation of new benchmarks.

### Stratification and context-dependent benchmarking

As benchmarks become more comprehensive, stratification by genome context and
variant type becomes increasingly important. Methods optimized for clinical
coding regions may not need high accuracy in satellite DNA or very long
homopolymers, while the precise length of G or C homopolymers in promoters
may be more relevant than polyA tails in Alus and LINEs. The v5.0 benchmark
enables more nuanced performance assessment through its genomic context
annotations, allowing users to evaluate accuracy in the specific regions most
relevant to their application. This is particularly valuable for difficult
regions newly included in v5.0, where variant calling accuracy varies widely
across technologies and pipelines.

### Complementary benchmarking approaches

This work complements the Platinum Pedigree benchmark, which expanded upon
GIAB v4.2.1 for HG001 using short and long reads from a large family pedigree.
While both benchmarks cover similar genome fractions and variant counts, our
assembly-based approach produces far fewer, larger benchmark regions (fewer
than 30,000 for small variants vs. over one million in the Platinum Pedigree),
which is advantageous for benchmarking complex variants in repetitive regions
that can have different representations. Conversely, the blood-based sequencing
used for the Platinum Pedigree provides more robust handling of de novo
variants without cell line artifacts. We expect these benchmarks to be
complementary due to their differences in construction method, DNA source,
sample ancestry and sex, and filtering processes.

This work also accompanies a companion manuscript proposing the HG002 Q100
assembly itself as a genome benchmark. In the genome benchmarking paradigm,
assembly evaluation is simpler and more comprehensive by directly comparing
assembly sequences rather than converting them to variant calls. The variant
benchmarking approach used here provides false positive, false negative, and
genotype error metrics that may be more directly relevant to downstream
applications. However, genome benchmarking complements variant benchmarks by
enabling assessment in regions excluded from variant benchmarks due to
challenges in variant representation and comparison. Future work integrating
pangenomics or specialized tools may enable some of these regions to be
included in variant benchmarks.

### Limitations

Despite the high accuracy of the Q100 assembly, several categories of genomic
regions remain excluded from this benchmark. Complex structural variation
involving large copy number differences, nested duplications, and multi-allelic
rearrangements cannot be reliably represented in VCF format or compared by
current benchmarking tools. Regions such as the SMN1/SMN2 locus, the DAZ locus
on chrY, and large inversions mediated by segmental duplications (e.g., PMS2)
are excluded because assembly-to-reference alignment is ambiguous or variant
representation is undefined. These limitations are inherent to the current
paradigm of representing variation relative to a linear reference and
benchmarking with pairwise comparison tools.

The use of a cell line (GM24385) as the DNA source introduces potential
artifacts from somatic mutations and cell culture-induced mosaicism. We
mitigate this by excluding known mosaic variants and regions, and our
exclusion approach captured all recently identified mosaic variants in HG002.
However, new mosaic variants may arise in future cell line batches, and users
should be aware that the benchmark represents the cell line rather than the
original blood sample.

The benchmark is currently limited to a single individual of Ashkenazi Jewish
ancestry. While HG002 was selected for its extensive public resources and
broad consent, population-specific variation is not represented. The v5.0
benchmark shares this limitation with all current whole-genome variant
benchmarks, though the DeFrABB framework is designed to facilitate generation
of benchmarks from other individuals as high-quality assemblies become
available.

### Future directions

The DeFrABB pipeline and the approaches developed for this benchmark lay the
groundwork for several future efforts. As additional GIAB reference materials
receive high-quality diploid assemblies, matched variant benchmarks can be
generated for multiple individuals, enabling assessment of variant calling
across diverse genetic backgrounds. Assembly improvements, such as the
corrections in the Q100 v1.1 assembly, can be rapidly incorporated into
updated benchmarks. Advances in variant representation standards and
benchmarking tools for complex structural variation may eventually allow
inclusion of currently excluded regions.

### Conclusion

The GIAB HG002 v5.0 variant benchmark provides a comprehensive resource for
evaluating variant calling across the vast majority of the human genome,
including many challenging regions excluded from previous benchmarks. By
making draft benchmarks publicly available during development, this work has
already contributed to improvements in variant calling tools and benchmarking
methods. The DeFrABB framework ensures reproducibility and extensibility,
supporting the generation of future benchmarks as assemblies, references, and
standards continue to improve.